{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e4fbf21",
   "metadata": {},
   "source": [
    "### Project Outline\n",
    "This project is to deeply understand dog-rating tweets posted on \"We Rate Dogs\", as a part of data wrangling project at Udacity. The datasets consist of three tables- Archived tweets, Image prediction, and JSON file which has been gathered via Twitter API.\n",
    "\n",
    "The project process is as follow; Gathering data, Visual & Programmatic assessment, Data cleaning and Analysis.\n",
    "\n",
    "### Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce05e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab5094b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_arc_raw = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "959ce271",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = requests.get(url)\n",
    "\n",
    "with open (url.split('/')[-1], mode='wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a31c33f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_raw = pd.read_csv('image-predictions.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e6bf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'HIDDEN'\n",
    "consumer_secret = 'HIDDEN'\n",
    "access_token = 'HIDDEN'\n",
    "access_secret = 'HIDDEN'\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "tweet_ids = twit_arc_raw.tweet_id.values\n",
    "len(tweet_ids)\n",
    "\n",
    "# Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "count = 0\n",
    "fails_dict = {}\n",
    "start = timer()\n",
    "# Save each tweet's returned JSON as a new line in a .txt file\n",
    "with open('tweet_json.txt', 'w') as outfile:\n",
    "    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "    for tweet_id in tweet_ids:\n",
    "        count += 1\n",
    "        print(str(count) + \": \" + str(tweet_id))\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            print(\"Success\")\n",
    "            json.dump(tweet._json, outfile)\n",
    "            outfile.write('\\n')\n",
    "        except tweepy.TweepError as e:\n",
    "            print(\"Fail\")\n",
    "            fails_dict[tweet_id] = e\n",
    "            pass\n",
    "end = timer()\n",
    "print(end - start)\n",
    "print(fails_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed78979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_json_raw = pd.read_json('tweet-json.txt', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
